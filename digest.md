# Weekly ToC Digest (week of 2026-02-16)

Prioritized based on relevance to wavelet design, multiresolution analysis, and deep learning integration. Prioritized wavelet-based methods and those at the intersection of signal processing and deep learning for applications relevant to the user's research interests. Focusing on signal processing advancements and novel integrations between classical methods and deep learning. This week's prioritized articles focus on developments in signal processing and theoretical advances with relevance to deep learning and harmonic analysis.

**Included:** 19 (score ≥ 0.35)  
**Scored:** 19 total items

---

## [VDW-GNNs: Vector diffusion wavelets for geometric graph neural networks](https://arxiv.org/abs/2510.01022)
*arXiv Signal Processing*  
Score: **0.95**  
Published: 2026-02-16T05:00:00+00:00
Tags: wavelets, graph-nn, theory

Introduces vector diffusion wavelets, integrating wavelets into graph neural networks, useful for data on Riemannian manifolds, aligning with wavelet theory and deep learning.

<details>
<summary>RSS summary</summary>

arXiv:2510.01022v2 Announce Type: replace-cross Abstract: We introduce vector diffusion wavelets (VDWs), a novel family of wavelets inspired by the vector diffusion maps algorithm that was introduced to analyze data lying in the tangent bundle of a Riemannian manifold. We show that these wavelets may be effectively incorporated into a family of geometric graph neural networks, which we refer to as VDW-GNNs. We demonstrate that such networks are effective on synthetic point cloud data, as well as…

</details>

---

## [Neural Evolutionary Kernel Method: A Knowledge-Guided Framework for Solving Evolutionary PDEs](https://arxiv.org/abs/2602.12872)
*arXiv Math*  
Score: **0.85**  
Published: 2026-02-16T05:00:00+00:00
Tags: PDE, deep-learning, methods

Uses deep neural networks for operator learning, linking to approximation in PDEs, relevant for deep learning and classical techniques.

<details>
<summary>RSS summary</summary>

arXiv:2602.12872v1 Announce Type: new Abstract: Numerical solution of partial differential equations (PDEs) plays a vital role in various fields of science and engineering. In recent years, deep neural networks (DNNs) have emerged as a powerful tool for solving PDEs, leveraging their approximation capabilities to handle complex domains and high-dimensional problems. Among these, operator learning has gained increasing attention by learning mappings between function spaces using DNNs. This paper …

</details>

---

## [OptiML: An End-to-End Framework for Program Synthesis and CUDA Kernel Optimization](https://arxiv.org/abs/2602.12305)
*arXiv AI*  
Score: **0.85**  
Published: 2026-02-16T05:00:00+00:00
Tags: methods, sparse, theory

This paper presents a framework integrating natural-language inputs with CUDA optimization, relevant for sparse coding and learnable basis functions in signal processing.

<details>
<summary>RSS summary</summary>

arXiv:2602.12305v1 Announce Type: cross Abstract: Generating high-performance CUDA kernels remains challenging due to the need to navigate a combinatorial space of low-level transformations under noisy and expensive hardware feedback. Although large language models can synthesize functionally correct CUDA code, achieving competitive performance requires systematic exploration and verification of optimization choices. We present OptiML, an end-to-end framework that maps either natural-language in…

</details>

---

## [Temporal-Stability-Enhanced and Energy-Stable Dynamical Low-Rank Approximation for Multiscale Linear Kinetic Transport Equations](https://arxiv.org/abs/2602.12337)
*arXiv Math*  
Score: **0.75**  
Published: 2026-02-16T05:00:00+00:00
Tags: multiscale, MRA, methods

Focuses on multiscale analysis and low-rank representation, relevant to multiresolution techniques commonly used in signal processing.

<details>
<summary>RSS summary</summary>

arXiv:2602.12337v1 Announce Type: new Abstract: In this paper, we develop an asymptotic-preserving dynamical low-rank method for the multiscale linear kinetic transport equation. The proposed scheme is unconditionally stable in the diffusive regime while preserving the correct asymptotic behavior, and can achieve significant reductions in computational cost through a low-rank representation and large time step stability. A low-rank formulation consistent with the discrete energy is introduced un…

</details>

---

## [Compressible Dynamics in Deep Overparameterized Low-Rank Learning & Adaptation](https://arxiv.org/abs/2406.04112)
*arXiv Signal Processing*  
Score: **0.75**  
Published: 2026-02-16T05:00:00+00:00
Tags: sparse, deep-learning, low-rank

Highlights compressible dynamics in deep learning, leveraging low-dimensional structures, relevant to sparse coding and representation learning techniques.

<details>
<summary>RSS summary</summary>

arXiv:2406.04112v3 Announce Type: replace-cross Abstract: While overparameterization in machine learning models offers great benefits in terms of optimization and generalization, it also leads to increased computational requirements as model sizes grow. In this work, we show that by leveraging the inherent low-dimensional structures of data and compressible dynamics within the model parameters, we can reap the benefits of overparameterization without the computational burdens. In practice, we de…

</details>

---

## [Detecting Object Tracking Failure via Sequential Hypothesis Testing](https://arxiv.org/abs/2602.12983)
*arXiv Computer Vision*  
Score: **0.75**  
Published: 2026-02-16T05:00:00+00:00
Tags: theory, time-frequency, methods

Proposal of sequential hypothesis testing could benefit signal decomposition methodologies, enhancing classical signal analysis frameworks.

<details>
<summary>RSS summary</summary>

arXiv:2602.12983v1 Announce Type: new Abstract: Real-time online object tracking in videos constitutes a core task in computer vision, with wide-ranging applications including video surveillance, motion capture, and robotics. Deployed tracking systems usually lack formal safety assurances to convey when tracking is reliable and when it may fail, at best relying on heuristic measures of model confidence to raise alerts. To obtain such assurances we propose interpreting object tracking as a sequen…

</details>

---

## [TFT-ACB-XML: Decision-Level Integration of Customized Temporal Fusion Transformer and Attention-BiLSTM with XGBoost Meta-Learner for BTC Price Forecasting](https://arxiv.org/abs/2602.12380)
*arXiv AI*  
Score: **0.72**  
Published: 2026-02-16T05:00:00+00:00
Tags: time-frequency, methods, theory

This hybrid model uses deep learning techniques to analyze time-series, aligning with interests in modern signal processing methods.

<details>
<summary>RSS summary</summary>

arXiv:2602.12380v1 Announce Type: cross Abstract: Accurate forecasting of Bitcoin (BTC) has always been a challenge because decentralized markets are non-linear, highly volatile, and have temporal irregularities. Existing deep learning models often struggle with interpretability and generalization across diverse market conditions. This research presents a hybrid stacked-generalization framework, TFT-ACB-XML, for BTC closing price prediction. The framework integrates two parallel base learners: a…

</details>

---

## [Data-Driven Filter Design for Flexible and Noise-Robust Tomographic Imaging](https://arxiv.org/abs/2602.13048)
*arXiv Math*  
Score: **0.70**  
Published: 2026-02-16T05:00:00+00:00
Tags: filter, adaptive, sparse

Develops learning-based filter design, integrating data-driven methods with classical filtered back projection. Relevant for adaptive representations.

<details>
<summary>RSS summary</summary>

arXiv:2602.13048v1 Announce Type: new Abstract: While filtered back projection (FBP) is still the method of choice for fast tomographic reconstruction, its performance degrades noticeably in the presence of noise, incomplete sampling, or non-standard scan geometries. We propose a data-driven approach for learning FBP filters and projection weights directly from training data, with the goal of improving robustness without sacrificing computational efficiency. The resulting reconstructions adapt n…

</details>

---

## [SLA2: Sparse-Linear Attention with Learnable Routing and QAT](https://arxiv.org/abs/2602.12675)
*arXiv Machine Learning*  
Score: **0.70**  
Published: 2026-02-16T05:00:00+00:00
Tags: sparse, signal-processing, methods

The paper introduces Sparse-Linear Attention (SLA), optimizing attention mechanisms with a potential application in multi-resolution signal processing.

<details>
<summary>RSS summary</summary>

arXiv:2602.12675v1 Announce Type: new Abstract: Sparse-Linear Attention (SLA) combines sparse and linear attention to accelerate diffusion models and has shown strong performance in video generation. However, (i) SLA relies on a heuristic split that assigns computations to the sparse or linear branch based on attention-weight magnitude, which can be suboptimal. Additionally, (ii) after formally analyzing the attention error in SLA, we identify a mismatch between SLA and a direct decomposition in…

</details>

---

## [WebClipper: Efficient Evolution of Web Agents with Graph-based Trajectory Pruning](https://arxiv.org/abs/2602.12852)
*arXiv AI*  
Score: **0.70**  
Published: 2026-02-16T05:00:00+00:00
Tags: methods, theory

Graph-based pruning in this paper could inform adaptive representations and signal analysis models.

<details>
<summary>RSS summary</summary>

arXiv:2602.12852v1 Announce Type: new Abstract: Deep Research systems based on web agents have shown strong potential in solving complex information-seeking tasks, yet their search efficiency remains underexplored. We observe that many state-of-the-art open-source web agents rely on long tool-call trajectories with cyclic reasoning loops and exploration of unproductive branches. To address this, we propose WebClipper, a framework that compresses web agent trajectories via graph-based pruning. Co…

</details>

---

## [Evolving Beyond Snapshots: Harmonizing Structure and Sequence via Entity State Tuning for Temporal Knowledge Graph Forecasting](https://arxiv.org/abs/2602.12389)
*arXiv AI*  
Score: **0.68**  
Published: 2026-02-16T05:00:00+00:00
Tags: theory, time-frequency

Introduces a stateful approach for entity representation, potentially useful for temporal signal representation.

---

## [A versatile FEM framework with native GPU scalability via globally-applied AD](https://arxiv.org/abs/2602.12365)
*arXiv Math*  
Score: **0.65**  
Published: 2026-02-16T05:00:00+00:00
Tags: methods, computational, FEM

Involves automatic differentiation (AD) for energy-based methods, linking computational frameworks to advanced signal processing.

<details>
<summary>RSS summary</summary>

arXiv:2602.12365v1 Announce Type: new Abstract: Energy-based finite-element formulations provide a unified framework for describing complex physical systems in computational mechanics. In these energy-based methods, the governing equations can be obtained directly by considering the derivatives of a single global energy functional. While Automatic Differentiation (AD) can be used to automate the generation of these derivatives, current frameworks face a clear trade-off based primarily on the sca…

</details>

---

## [A Machine Learning Approach to the Nirenberg Problem](https://arxiv.org/abs/2602.12368)
*arXiv Machine Learning*  
Score: **0.65**  
Published: 2026-02-16T05:00:00+00:00
Tags: machine-learning, geometry, methods

Relevant for its application of a numerical approach to Nirenberg's problem using neural networks, potentially valuable for understanding complex signal geometries.

<details>
<summary>RSS summary</summary>

arXiv:2602.12368v1 Announce Type: new Abstract: This work introduces the Nirenberg Neural Network: a numerical approach to the Nirenberg problem of prescribing Gaussian curvature on $S^2$ for metrics that are pointwise conformal to the round metric. Our mesh-free physics-informed neural network (PINN) approach directly parametrises the conformal factor globally and is trained with a geometry-aware loss enforcing the curvature equation. Additional consistency checks were performed via the Gauss-B…

</details>

---

## [Fast convolution solvers using moment-matching](https://arxiv.org/abs/2602.12850)
*arXiv Math*  
Score: **0.60**  
Published: 2026-02-16T05:00:00+00:00
Tags: convolution, methods, signal-processing

Introduces efficient convolution algorithms relevant for signal processing applications.

<details>
<summary>RSS summary</summary>

arXiv:2602.12850v1 Announce Type: new Abstract: We propose two easy-to-implement fast algorithms based on moment-matching to compute the nonlocal potential $\varphi(\textbf{x})=(U\ast \rho)(\textbf{x})$ on bounded domain, where the kernel $U$ is singular at the origin and the density $\rho$ is a fast-decaying smooth function. Each method requires merely minor modifications to commonly-used existing methods, i.e., the sine spectral/Fourier quadrature method, and achieves a much better convergence…

</details>

---

## [Unifying Model-Free Efficiency and Model-Based Representations via Latent Dynamics](https://arxiv.org/abs/2602.12643)
*arXiv Machine Learning*  
Score: **0.60**  
Published: 2026-02-16T05:00:00+00:00
Tags: adaptive, methods, theory

Bridges model-free and model-based learning, embedding state-action pairs for signal analysis, relevant to adaptive representations.

<details>
<summary>RSS summary</summary>

arXiv:2602.12643v1 Announce Type: new Abstract: We present Unified Latent Dynamics (ULD), a novel reinforcement learning algorithm that unifies the efficiency of model-free methods with the representational strengths of model-based approaches, without incurring planning overhead. By embedding state-action pairs into a latent space in which the true value function is approximately linear, our method supports a single set of hyperparameters across diverse domains -- from continuous control with lo…

</details>

---

## [Self-Supervised Temporal Super-Resolution of Energy Data using Generative Adversarial Transformer](https://arxiv.org/abs/2508.10587)
*arXiv Signal Processing*  
Score: **0.55**  
Published: 2026-02-16T05:00:00+00:00
Tags: time-series, GAN, signal-processing

Focuses on time-series data resampling using GANs, connecting signal processing with machine learning innovations.

<details>
<summary>RSS summary</summary>

arXiv:2508.10587v4 Announce Type: replace-cross Abstract: To bridge the temporal granularity gap in energy network design and operation based on Energy System Models, resampling of time series is required. While conventional upsampling methods are computationally efficient, they often result in significant information loss or increased noise. Advanced models such as time series generation models, Super-Resolution models and imputation models show potential, but also face fundamental challenges. …

</details>

---

## [High-dimensional Level Set Estimation with Trust Regions and Double Acquisition Functions](https://arxiv.org/abs/2602.12391)
*arXiv Machine Learning*  
Score: **0.50**  
Published: 2026-02-16T05:00:00+00:00
Tags: high-dimensional, methods, signal-processing

Presents a method for iterative acquisition in high-dimensional spaces, valuable for enhancing signal processing models in complex environments.

<details>
<summary>RSS summary</summary>

arXiv:2602.12391v1 Announce Type: new Abstract: Level set estimation (LSE) classifies whether an unknown function's value exceeds a specified threshold for given inputs, a fundamental problem in many real-world applications. In active learning settings with limited initial data, we aim to iteratively acquire informative points to construct an accurate classifier for this task. In high-dimensional spaces, this becomes challenging where the search volume grows exponentially with increasing dimensi…

</details>

---

## [Channel-Aware Probing for Multi-Channel Imaging](https://arxiv.org/abs/2602.12696)
*arXiv Computer Vision*  
Score: **0.50**  
Published: 2026-02-16T05:00:00+00:00
Tags: methods, filter-bank, adaptive

Explores using frozen encoders with multi-channel data, relevant to adaptive filtering and sparsity in signal processing.

---

## [QuEPT: Quantized Elastic Precision Transformers with One-Shot Calibration for Multi-Bit Switching](https://arxiv.org/abs/2602.12609)
*arXiv Computer Vision*  
Score: **0.40**  
Published: 2026-02-16T05:00:00+00:00
Tags: quantization, methods, CNN

Innovative quantization method applicable to multiresolution analysis in neural networks.

<details>
<summary>RSS summary</summary>

arXiv:2602.12609v1 Announce Type: new Abstract: Elastic precision quantization enables multi-bit deployment via a single optimization pass, fitting diverse quantization scenarios.Yet, the high storage and optimization costs associated with the Transformer architecture, research on elastic quantization remains limited, particularly for large language models.This paper proposes QuEPT, an efficient post-training scheme that reconstructs block-wise multi-bit errors with one-shot calibration on a sma…

</details>

---
